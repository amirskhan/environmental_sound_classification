{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682acdeb-5c4b-4f37-ad70-2f95341a7e5e",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de91915-09ce-4057-822e-52938188b1ad",
   "metadata": {},
   "source": [
    "After the data has been pre-processed and converted into train test sets, the train set can be used for training the model. In this step the algorithm maps the features or the independent variables to the output dependent variable. I will train multiple algorithms and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83509942",
   "metadata": {},
   "source": [
    "## Artificial Neural Netwroks (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6051f-f9ea-4636-a0b7-2cbadb882fce",
   "metadata": {},
   "source": [
    "ANN is simply called neural networks. It is a collection of connected nodes. It performs better than traditional machine learning algorithms in most cases. First, I will use it to train only with MFCC features, and then I will train it with the combined features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907c6fe-4470-472b-8947-81c132515e19",
   "metadata": {},
   "source": [
    "### Train with MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17a4e4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e795ca-0cb4-4370-ba22-6d90603a6ea7",
   "metadata": {},
   "source": [
    "Here, we set the input shape to be entered at the first layer of the neural network. And the number of outputs is set to the number of classes the model has to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d452abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec4dd5-62a4-4ea1-9e58-109daad27607",
   "metadata": {},
   "source": [
    "The model is initialised with the sequential class from Keras. The first layer consists of 500 hundred units of neurons with relu activation function and input shape. The number of units in a layer is mostly based on trial and error. There is no fixed methodology. It is only with experience one can understand how these numbers relates. But usually for dense layers, the number of units should start with a large number and then should decrease with further layers. This network consists of 6 dense layers. The second, third, fourth and fifth layers have 400, 300, 200, and 100 units of neurons respectively. All these layers have relu activation function. In previous experimentations Relu activation functions have performed better and gives good results. A dropout of 30% percent is added before the last output layer to prevent overfitting of the model. The last output layer consists of the 10 units as the number of classes and a softmax activation function. Softmax activation function is used for multiclass classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9164660-991f-4403-bd55-52876061dbbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 23:22:23.996973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-18 23:22:24.040647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.041266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-04-18 23:22:24.041430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-18 23:22:24.042637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-18 23:22:24.043742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-18 23:22:24.043937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-18 23:22:24.044902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-18 23:22:24.045506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-18 23:22:24.047989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-18 23:22:24.048117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.048785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.049340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-04-18 23:22:24.049539: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-04-18 23:22:24.073730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3699850000 Hz\n",
      "2022-04-18 23:22:24.074364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561cb6956790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-18 23:22:24.074377: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-18 23:22:24.133131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.133751: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561cb75f4880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-18 23:22:24.133763: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2022-04-18 23:22:24.133920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.134476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-04-18 23:22:24.134515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-18 23:22:24.134531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-18 23:22:24.134546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-18 23:22:24.134563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-18 23:22:24.134578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-18 23:22:24.134593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-18 23:22:24.134608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-18 23:22:24.134659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.135233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.135763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-04-18 23:22:24.135795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-18 23:22:24.136445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-18 23:22:24.136453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-04-18 23:22:24.136456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-04-18 23:22:24.136530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.137109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 23:22:24.137669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22546 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               10500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 412,510\n",
      "Trainable params: 412,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# drop 30% neurons\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "# check model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09f184-6b2a-4709-8afe-04bc56663b77",
   "metadata": {},
   "source": [
    "The model is set and compiled with a loss function, optimiser, and evaluation metric.\n",
    "* Categorical crossentropy: It is a loss function used with multiclass classification problems.\n",
    "* Adam: It is an optimised algorithm that contains the best properties of AdaGrad and RMSProp algorithms. It performs better on complex data such as images and audio.\n",
    "* Accuracy: It is a standard evaluation metric which is used with almost every model for evaluation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14c18adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a79a0-7b95-4b8b-b21f-d62b04b7654d",
   "metadata": {},
   "source": [
    "The number of epochs depends on the complexity of data and model architecture. It is high for complex problems such as object detection and low for simple problems. 100 is a good number for a mid level problem. Also, I am using Early stopping function from Keras which will automatically stop the training if the validation loss is not dropping for a set number of steps. In early stopping function we can set the monitor method and patience level. I will set it to monitor validation loss and set patience level to 25, means, if there is no improvement in 25 epochs, the training will stop. Early stopping function helps to prevent overfitting of the model. The batch size is set to 32 based on the system resources and the quantity of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cad62b7e-e150-4edc-bf3a-192baae67d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0fdf6b-c34f-4ae4-9a21-8066c0b676d9",
   "metadata": {},
   "source": [
    "All the parameters will be loaded and the model will start training with the fit method. The training history will be saved so that it can be used for evaluation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1925eedd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 23:27:43.467081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 0s 2ms/step - loss: 2.1225 - accuracy: 0.3279 - val_loss: 1.5313 - val_accuracy: 0.5153\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 1.4889 - accuracy: 0.4902 - val_loss: 1.3202 - val_accuracy: 0.5598\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 1.2543 - accuracy: 0.5771 - val_loss: 1.2908 - val_accuracy: 0.6005\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 1.0713 - accuracy: 0.6407 - val_loss: 0.9899 - val_accuracy: 0.6552\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.9210 - accuracy: 0.6893 - val_loss: 0.8847 - val_accuracy: 0.7125\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.7716 - accuracy: 0.7410 - val_loss: 0.7432 - val_accuracy: 0.7646\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.7735 - val_loss: 0.7143 - val_accuracy: 0.7710\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.7972 - val_loss: 0.6587 - val_accuracy: 0.7850\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.8207 - val_loss: 0.6261 - val_accuracy: 0.8168\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8344 - val_loss: 0.6149 - val_accuracy: 0.8079\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.8518 - val_loss: 0.5590 - val_accuracy: 0.8244\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8730 - val_loss: 0.5641 - val_accuracy: 0.8321\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8681 - val_loss: 0.4603 - val_accuracy: 0.8524\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8932 - val_loss: 0.4311 - val_accuracy: 0.8791\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.9007 - val_loss: 0.4440 - val_accuracy: 0.8690\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.9091 - val_loss: 0.4541 - val_accuracy: 0.8524\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.9096 - val_loss: 0.5267 - val_accuracy: 0.8601\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9269 - val_loss: 0.5095 - val_accuracy: 0.8588\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9258 - val_loss: 0.5457 - val_accuracy: 0.8639\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9212 - val_loss: 0.4677 - val_accuracy: 0.8753\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9314 - val_loss: 0.4352 - val_accuracy: 0.8830\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9392 - val_loss: 0.4702 - val_accuracy: 0.8830\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9395 - val_loss: 0.4589 - val_accuracy: 0.8791\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9424 - val_loss: 0.4301 - val_accuracy: 0.8969\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9525 - val_loss: 0.3953 - val_accuracy: 0.9046\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9436 - val_loss: 0.4540 - val_accuracy: 0.8995\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9515 - val_loss: 0.4049 - val_accuracy: 0.8906\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9540 - val_loss: 0.4110 - val_accuracy: 0.8995\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9648 - val_loss: 0.4385 - val_accuracy: 0.9059\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9525 - val_loss: 0.3898 - val_accuracy: 0.9020\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9663 - val_loss: 0.3973 - val_accuracy: 0.9097\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9663 - val_loss: 0.4483 - val_accuracy: 0.9020\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9514 - val_loss: 0.4406 - val_accuracy: 0.8893\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9651 - val_loss: 0.4388 - val_accuracy: 0.9084\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9697 - val_loss: 0.4452 - val_accuracy: 0.9071\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9631 - val_loss: 0.4821 - val_accuracy: 0.8944\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9689 - val_loss: 0.5808 - val_accuracy: 0.8944\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9671 - val_loss: 0.4680 - val_accuracy: 0.8969\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9779 - val_loss: 0.5342 - val_accuracy: 0.9020\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9767 - val_loss: 0.6089 - val_accuracy: 0.9059\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9589 - val_loss: 0.5146 - val_accuracy: 0.8957\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9628 - val_loss: 0.5115 - val_accuracy: 0.8817\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9634 - val_loss: 0.5658 - val_accuracy: 0.8880\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9738 - val_loss: 0.5282 - val_accuracy: 0.8995\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9720 - val_loss: 0.4446 - val_accuracy: 0.9097\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9826 - val_loss: 0.4999 - val_accuracy: 0.9249\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9731 - val_loss: 0.4084 - val_accuracy: 0.9186\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9743 - val_loss: 0.5430 - val_accuracy: 0.8766\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9753 - val_loss: 0.5538 - val_accuracy: 0.8995\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9755 - val_loss: 0.5510 - val_accuracy: 0.9033\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9791 - val_loss: 0.4798 - val_accuracy: 0.9148\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9740 - val_loss: 0.6041 - val_accuracy: 0.8855\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9576 - val_loss: 0.4625 - val_accuracy: 0.9122\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9822 - val_loss: 0.4610 - val_accuracy: 0.9122\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9857 - val_loss: 0.5508 - val_accuracy: 0.9122\n",
      "Epoch 00055: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cd00c-bd7d-4689-93b5-966f05c6a482",
   "metadata": {},
   "source": [
    "The model is giving a good accuracy score of 90%. In the next section I will train with the combined features and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98a1f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 858us/step - loss: 0.5029 - accuracy: 0.9073\n",
      "[0.5028848648071289, 0.9073226451873779]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103dff2-f1c6-49f2-8588-e1ca73352508",
   "metadata": {},
   "source": [
    "### Train with combined features of Melspectrogram and MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05eb7fb-7bc2-43a2-a622-992cfa0c6496",
   "metadata": {},
   "source": [
    "The train test and validation sets will be created again on the concatenated feature array which was created in the preprocessing step. Their shapes will be printed to check their dimensions. The input shape to be entered at the first layer of neural network will be updated with the new input dimension. The model architecture will be kept same as I want to compare if the combined features are improving the accuracy or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40964ee4-acfd-410b-8c7a-211e009ea03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6985, 148) (6985, 10)\n",
      "(1397, 148) (1397, 10)\n",
      "(350, 148) (350, 10)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 500)               74500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 476,510\n",
      "Trainable params: 476,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create train test validation sets on the concatenated features array\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(concat_arr, label_arr, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# update input shape\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# drop 30% neurons\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "# check model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b5e5e-98f6-40b9-90dc-8c5475ece08b",
   "metadata": {},
   "source": [
    "The model parameters are all same as the previous experimentaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5bbe10a-891b-46ee-8d53-7dee980660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "921203f2-cf67-4466-ac58-4a0ca2e4bcf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 2.0921 - accuracy: 0.3148 - val_loss: 1.6873 - val_accuracy: 0.4302\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.4967 - accuracy: 0.4893 - val_loss: 1.2649 - val_accuracy: 0.5777\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.1895 - accuracy: 0.5984 - val_loss: 1.2232 - val_accuracy: 0.6149\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 1.0500 - accuracy: 0.6584 - val_loss: 0.9132 - val_accuracy: 0.7180\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.8815 - accuracy: 0.7132 - val_loss: 0.8682 - val_accuracy: 0.7044\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.7459 - val_loss: 0.7259 - val_accuracy: 0.7666\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.7781 - val_loss: 0.7002 - val_accuracy: 0.7903\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.8109 - val_loss: 0.6688 - val_accuracy: 0.8067\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8301 - val_loss: 0.5326 - val_accuracy: 0.8454\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.8339 - val_loss: 0.5772 - val_accuracy: 0.8225\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8606 - val_loss: 0.4844 - val_accuracy: 0.8661\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8710 - val_loss: 0.4877 - val_accuracy: 0.8533\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8909 - val_loss: 0.5249 - val_accuracy: 0.8425\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9072 - val_loss: 0.4911 - val_accuracy: 0.8454\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8992 - val_loss: 0.4079 - val_accuracy: 0.8869\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.9165 - val_loss: 0.4384 - val_accuracy: 0.8790\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.9122 - val_loss: 0.4481 - val_accuracy: 0.8726\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.9161 - val_loss: 0.4915 - val_accuracy: 0.8712\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9247 - val_loss: 0.4899 - val_accuracy: 0.8812\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9270 - val_loss: 0.4470 - val_accuracy: 0.8740\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9314 - val_loss: 0.4650 - val_accuracy: 0.8883\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9476 - val_loss: 0.4760 - val_accuracy: 0.8905\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9412 - val_loss: 0.4955 - val_accuracy: 0.8869\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9432 - val_loss: 0.4204 - val_accuracy: 0.8941\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9497 - val_loss: 0.5225 - val_accuracy: 0.8898\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9542 - val_loss: 0.5316 - val_accuracy: 0.9084\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9582 - val_loss: 0.6593 - val_accuracy: 0.8733\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9480 - val_loss: 0.4543 - val_accuracy: 0.8898\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9602 - val_loss: 0.5563 - val_accuracy: 0.9069\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9545 - val_loss: 0.4562 - val_accuracy: 0.9026\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9649 - val_loss: 0.5427 - val_accuracy: 0.8941\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9664 - val_loss: 0.5883 - val_accuracy: 0.9012\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9681 - val_loss: 0.5028 - val_accuracy: 0.9134\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9719 - val_loss: 0.5602 - val_accuracy: 0.9048\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9696 - val_loss: 0.5385 - val_accuracy: 0.8991\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9659 - val_loss: 0.7399 - val_accuracy: 0.8912\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9596 - val_loss: 0.6012 - val_accuracy: 0.8919\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9598 - val_loss: 0.5078 - val_accuracy: 0.9155\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9679 - val_loss: 0.4915 - val_accuracy: 0.9069\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9762 - val_loss: 0.4452 - val_accuracy: 0.9105\n",
      "Epoch 00040: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "026c17b1-c261-4de3-8613-e6ec4afb2288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 896us/step - loss: 0.3717 - accuracy: 0.9343\n",
      "[0.37172171473503113, 0.9342857003211975]\n"
     ]
    }
   ],
   "source": [
    "score_2 = model.evaluate(X_test, y_test)\n",
    "print(score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b60538-3f72-4319-88c3-64a5c09f83e0",
   "metadata": {},
   "source": [
    "The combined features of Melspectrogram and MFCC gives a very good result and improves the accuracy score to 93%. I will save this model to be used later for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75bc4dad-6650-44e0-a97a-9d8cf32f9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ann_detector.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec7446-d51d-4f1b-aadc-ba57313341b2",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7a5ce-e373-48ec-823c-0774127593fb",
   "metadata": {},
   "source": [
    "Now, I will train a Random Forest algorithm and see how it performs on this audio data. Random Forest classifier will be imported from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8402a93-66e7-4e4c-916c-0b265d8b5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f6c05-098d-45ba-8b7f-79c2d171ab5b",
   "metadata": {},
   "source": [
    "The train and test sets will be created for Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadcffb-fd50-467a-9ae5-0fe78ba91a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(mfcc_arr, label_arr, test_size=0.2, random_state=456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d27d2-d05b-4421-bc3c-0eebe77ae6a1",
   "metadata": {},
   "source": [
    "THe parameters for Random Forest are duscussed below.\n",
    "* n_estimators: It is the number of trees to be used in the forest. 100 is a default value, but i will keep it to 500 hundred as the data is high dimensional. And increasing this value further will overfit the model. So, 500 is a good value. \n",
    "* max_depth: The defualt is none, but I will keep it to 10. Increasing this value for a high dimensional data will allow model to learn more complex features but will increase training time a lot. \n",
    "* random_state: Seed used for Random Number Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50644b60-d9d2-4d4b-b28a-b980abe7b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 500, # default value is 100\n",
    "    'max_depth': 10, # will keep it to 10\n",
    "    'random_state': 123 # Seed used for Random Number Generator\n",
    "}\n",
    "rf_model = RandomForestClassifier(**rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63614eaa-5e10-4321-99ef-0f0864d5c0ce",
   "metadata": {},
   "source": [
    "The fit method will start the training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a47fe10-6085-43aa-b685-c68c314de82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=500, random_state=123)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5dea78-7e0d-4cc0-9bac-dec7d80d3e50",
   "metadata": {},
   "source": [
    "Let's use the predict method of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e23cb6ca-3801-4c77-bb78-36b262446f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the predict method on test set\n",
    "rf_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0918d689-75b3-4272-aa63-4981ebcf2cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.48\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9be3e-3d05-44b8-8273-d5286a8623ae",
   "metadata": {},
   "source": [
    "The accuracy is poor. Let's train it with the combined features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d0841-70b3-4a69-a5a4-c24bb02e56b1",
   "metadata": {},
   "source": [
    "### Train with combined features of Melspectrogram and MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a822b-2217-4440-8af4-5e7918b0cf83",
   "metadata": {},
   "source": [
    "The train and test sets are created with the concatenated array. This time I make some changes in the parameters because the data is complex and the complexity of the model has to be increased in order to fit the data properly. \n",
    "* n_estimators is increased to 1000 to increase more trees so that the model can learn more features.\n",
    "* max_depth is increased to 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea922096-a1c5-4078-a809-ea5ef18555df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6985, 148) (6985, 10)\n",
      "(1747, 148) (1747, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=1000, random_state=123)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(concat_arr, label_arr, test_size=0.2, random_state=234)\n",
    "# print shapes of train and test sets\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "# create model and set parameters\n",
    "rf_params_2 = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 20,\n",
    "    'random_state': 123 # Seed used for Random Number Generator\n",
    "}\n",
    "rf_model_2 = RandomForestClassifier(**rf_params_2)\n",
    "# train model\n",
    "rf_model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7529f633-8bcf-4243-bdee-0c7adace8eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6628506010303378\n"
     ]
    }
   ],
   "source": [
    "# using the predict method on test set\n",
    "rf_pred_2 = rf_model_2.predict(X_test)\n",
    "print('Accuracy score: ', accuracy_score(y_test, rf_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e80fb7-df57-4149-86ac-41a53b6a3b98",
   "metadata": {},
   "source": [
    "The accuracy has improved a lot with the combined features. But it is still lower than the ANN accuracy. The model will be saved using the joblib library dump function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e73e48aa-d438-4e44-87a1-db6cfc9424bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_detector.joblib']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf_model_2, 'rf_detector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2c378-0c5f-46be-87fe-a78c40c05587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12f398f55b82d715cae46ff9b30516ca117e39e1bad45ee40367b5b480da2323"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
